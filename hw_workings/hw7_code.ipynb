{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T07:08:27.608308Z",
     "start_time": "2024-04-28T07:08:26.321190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:49:36) [Clang 16.0.6 ]\n",
      "Numpy version: 1.26.4\n",
      "Matplotlib version: 3.8.0\n",
      "PyTorch version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "print(f\"Python version: {sys.version}\\nNumpy version: {np.__version__}\\nMatplotlib version: {matplotlib.__version__}\\nPyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6910192788eeb465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T07:57:59.243804Z",
     "start_time": "2024-04-28T07:57:59.240540Z"
    }
   },
   "outputs": [],
   "source": [
    "CIFAR_DATA_PATH = \"/Users/lucah/Library/CloudStorage/OneDrive-DurhamUniversity/Course Material & Work/SNU Year Abroad {SNU}/2-Spring Semester/Mathematical Foundations of Deep Neural Networks {MFDNN}/Lectures Slides {MFDNN}/Notebooks {MFDNN}/cifar_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea8eaa",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a53cd",
   "metadata": {},
   "source": [
    "Originally,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4204c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000) :\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) :\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f4123b",
   "metadata": {},
   "source": [
    "Let's dissect it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "480161ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetDissect(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1000) :\n",
    "        super(AlexNetDissect, self).__init__()\n",
    "        self.features1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.features2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.features3 = nn.Sequential(\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.features4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.features5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) :\n",
    "        print('input', x.shape)\n",
    "        x = self.features1(x)\n",
    "        print('after f1', x.shape)\n",
    "        x = self.features2(x)\n",
    "        print('after f2', x.shape)\n",
    "        x = self.features3(x)\n",
    "        print('after f3', x.shape)\n",
    "        x = self.features4(x)\n",
    "        print('after f4', x.shape)\n",
    "        x = self.features5(x)\n",
    "        print('after f5', x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        print('after avg', x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier1(x)\n",
    "        print('after c1', x.shape)\n",
    "        x = self.classifier2(x)\n",
    "        print('after c2', x.shape)\n",
    "        x = self.classifier3(x)\n",
    "        print('after c3', x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "modeld = AlexNetDissect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ace7ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([1, 3, 227, 227])\n",
      "after f1 torch.Size([1, 64, 27, 27])\n",
      "after f2 torch.Size([1, 192, 13, 13])\n",
      "after f3 torch.Size([1, 384, 13, 13])\n",
      "after f4 torch.Size([1, 256, 13, 13])\n",
      "after f5 torch.Size([1, 256, 6, 6])\n",
      "after avg torch.Size([1, 256, 6, 6])\n",
      "after c1 torch.Size([1, 4096])\n",
      "after c2 torch.Size([1, 4096])\n",
      "after c3 torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "_ = modeld(torch.rand((1,3,227,227)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aab9a3212778c6e",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dafe37a408dbe4",
   "metadata": {},
   "source": [
    "## Instantiate model (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf0e8f9fd435ea59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T13:04:51.202750Z",
     "start_time": "2024-04-26T13:04:50.146155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Instantiate model with BN and load trained parameters\n",
    "class smallNetTrain(nn.Module) :\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16*32*32, 32*32),\n",
    "            nn.BatchNorm1d(32*32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(32*32, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.float().view(-1, 16*32*32)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = smallNetTrain()\n",
    "model.load_state_dict(torch.load(\"./smallNetSaved\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269a5247d7740deb",
   "metadata": {},
   "source": [
    "## Instantiate model without BN (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d050f43d35612acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T13:04:51.249914Z",
     "start_time": "2024-04-26T13:04:51.203608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate model without BN\n",
    "class smallNetTest(nn.Module) :\n",
    "    # CIFAR-10 data is 32*32 images with 3 RGB channels\n",
    "    def __init__(self, input_dim=3*32*32) :\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16*32*32, 32*32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(32*32, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.float().view(-1, 16*32*32)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model_test = smallNetTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af029a7cdfe9470",
   "metadata": {},
   "source": [
    "## Weight tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3334a0dff66da58c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T13:06:19.841747Z",
     "start_time": "2024-04-26T13:06:19.039665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor(1.1354e-07)\n"
     ]
    }
   ],
   "source": [
    "# Initialize weights of model without BN\n",
    "conv1_bn_beta, conv1_bn_gamma = model.conv1[1].bias, model.conv1[1].weight\n",
    "conv1_bn_mean, conv1_bn_var = model.conv1[1].running_mean, model.conv1[1].running_var\n",
    "\n",
    "conv2_bn_beta, conv2_bn_gamma = model.conv2[1].bias, model.conv2[1].weight\n",
    "conv2_bn_mean, conv2_bn_var = model.conv2[1].running_mean, model.conv2[1].running_var\n",
    "\n",
    "fc1_bn_beta, fc1_bn_gamma = model.fc1[1].bias, model.fc1[1].weight\n",
    "fc1_bn_mean, fc1_bn_var = model.fc1[1].running_mean, model.fc1[1].running_var\n",
    "\n",
    "eps = 1e-05\n",
    "\n",
    "\n",
    "# Initialize the following parameters\n",
    "trained_w = model.conv1[0].weight\n",
    "trained_b = model.conv1[0].bias\n",
    "std = torch.sqrt(conv1_bn_var+eps)\n",
    "model_test.conv1[0].weight.data = trained_w * conv1_bn_gamma.view(-1,1,1,1)/std.view(-1,1,1,1)\n",
    "model_test.conv1[0].bias.data = (trained_b - conv1_bn_mean) * conv1_bn_gamma/std + conv1_bn_beta\n",
    "\n",
    "trained_w = model.conv2[0].weight\n",
    "trained_b = model.conv2[0].bias\n",
    "std = torch.sqrt(conv2_bn_var+eps)\n",
    "model_test.conv2[0].weight.data = trained_w * conv2_bn_gamma.view(-1,1,1,1)/std.view(-1,1,1,1)\n",
    "model_test.conv2[0].bias.data = (trained_b - conv2_bn_mean) * conv2_bn_gamma/std + conv2_bn_beta\n",
    "\n",
    "trained_w = model.fc1[0].weight\n",
    "trained_b = model.fc1[0].bias\n",
    "std = torch.sqrt(fc1_bn_var+eps)\n",
    "model_test.fc1[0].weight.data = trained_w * fc1_bn_gamma.view(-1,1)/std.view(-1,1)\n",
    "model_test.fc1[0].bias.data = (trained_b - fc1_bn_mean) * fc1_bn_gamma/std + fc1_bn_beta\n",
    "\n",
    "trained_w = model.fc2[0].weight\n",
    "trained_b = model.fc2[0].bias\n",
    "model_test.fc2[0].weight.data = trained_w\n",
    "model_test.fc2[0].bias.data = trained_b\n",
    "\n",
    "# Verify difference between model and model_test\n",
    "model.eval()\n",
    "# model_test.eval()  # not necessary since model_test has no BN or dropout \n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=CIFAR_DATA_PATH,\n",
    "                                            train=False,\n",
    "                                            transform=transforms.ToTensor(), download = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "diff = []\n",
    "with torch.no_grad():\n",
    "    for images, _ in test_loader:\n",
    "        diff.append(torch.norm(model(images) - model_test(images))**2)\n",
    "\n",
    "print(max(diff)) # If less than 1e-08, you got the right answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718ff91",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1522794",
   "metadata": {},
   "source": [
    "## Net1 (given)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "807e6fbee1514b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T08:32:52.640214Z",
     "start_time": "2024-04-28T08:32:52.635299Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net1, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 18 * 18, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0235c",
   "metadata": {},
   "source": [
    "## (a) Net2 and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53a514c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T08:32:58.373522Z",
     "start_time": "2024-04-28T08:32:53.209152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pixel Difference: 9.708393194663781e-17\n"
     ]
    }
   ],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1),  # output 18x18 (for part (a))\n",
    "        )\n",
    "        # filled in\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(256, 4096, kernel_size=18, stride=1),  # output 1x1 (for part (a))\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4096, 4096, kernel_size=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4096, num_classes, kernel_size=1, stride=1)  # so that output is Bxnum_classesx1x1 (1 dimension removed by squeeze)\n",
    "        )\n",
    "\n",
    "    def copy_weights_from(self, net1):\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(self.features), 2):\n",
    "                self.features[i].weight.copy_(net1.features[i].weight)\n",
    "                self.features[i].bias.copy_(net1.features[i].bias)\n",
    "\n",
    "            for i in range(0, len(self.classifier), 2):  # skip ReLU layers\n",
    "                # filled in\n",
    "                linear_map = torch.clone(net1.classifier[i].weight.data)\n",
    "                k1, k2 = self.classifier[i].kernel_size\n",
    "                self.classifier[i].weight.data = torch.stack([row.reshape(-1, k1, k2) for row in linear_map])\n",
    "                # Or just this lol\n",
    "                # self.classifier[i].weight.copy_(\n",
    "                #     torch.reshape(net1.classifier[i].weight, self.classifier[i].weight.shape)\n",
    "                # )\n",
    "                \n",
    "                self.classifier[i].bias.data.copy_(net1.classifier[i].bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model1 = Net1() # model1 randomly initialized\n",
    "model2 = Net2()\n",
    "model2.copy_weights_from(model1)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=CIFAR_DATA_PATH,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=10\n",
    ")\n",
    "\n",
    "imgs, _ = next(iter(test_loader))\n",
    "diff = torch.mean((model1(imgs) - model2(imgs).squeeze()) ** 2)\n",
    "print(f\"Average Pixel Difference: {diff.item()}\") # should be small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35124d8c579eeeda",
   "metadata": {},
   "source": [
    "## (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56725517857c0f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T08:33:01.920926Z",
     "start_time": "2024-04-28T08:32:58.375333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Average Pixel Diff: 1.8988681379406458e-16\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=CIFAR_DATA_PATH,\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((36, 38)),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ]),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "images, _ = next(iter(test_loader))\n",
    "b, w, h = images.shape[0], images.shape[-1], images.shape[-2]\n",
    "out1 = torch.empty((b, 10, h - 31, w - 31))\n",
    "for i in range(h - 31):\n",
    "    for j in range(w - 31):\n",
    "        # filled in\n",
    "        out1[:, :, i, j] = model1(images[:,:,i:i+32,j:j+32])\n",
    "out2 = model2(images)\n",
    "diff = torch.mean((out1 - out2) ** 2)\n",
    "\n",
    "print(f\"Average Pixel Diff: {diff.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
